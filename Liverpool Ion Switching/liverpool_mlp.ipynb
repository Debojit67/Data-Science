{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "liverpool_mlp",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPJv2KLEKlzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth=GoogleAuth()\n",
        "gauth.credentials=GoogleCredentials.get_application_default()\n",
        "\n",
        "drive=GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ-Fqy3HKnFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_clean = drive.CreateFile({'id': '1_y2mSjhcw0uaI_vTgrLdd0UScWIEsjIb'})\n",
        "train_clean.GetContentFile('train_clean.csv')\n",
        "test_clean = drive.CreateFile({'id': '1U0g_7u7g61UTywF0elODU06jyJ_wLfjF'})\n",
        "test_clean.GetContentFile('test_clean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnnmBRjtKpLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = drive.CreateFile({'id': '1UAMpsYjI2161mmcs8MVsuEF-1okd43jT'})\n",
        "train.GetContentFile('train.csv')\n",
        "test = drive.CreateFile({'id': '17uPPXQbgzT772MCpsoddfEIYS95oGkD0'})\n",
        "test.GetContentFile('test.csv')\n",
        "sub = drive.CreateFile({'id': '1_48gjftaBNWfVd4DiMG4a7qQ-3Bv7P_N'})\n",
        "sub.GetContentFile('sample_submission.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXm01w7TKpGB",
        "colab_type": "code",
        "outputId": "0a373a77-2df7-45ed-84db-b80285e06d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "############################imports##########################################\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split,GroupKFold, KFold\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score, plot_confusion_matrix,mean_squared_error\n",
        "from keras.models import Model\n",
        "import keras.layers as L\n",
        "from keras.utils import to_categorical, plot_model\n",
        "\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "from scipy import signal\n",
        "\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVfLU4HbZzT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(X):\n",
        "  dataset = X.values\n",
        "  data_mean = dataset.mean(axis=0)\n",
        "  data_std = dataset.std(axis=0)\n",
        "  dataset = (dataset-data_mean)/data_std\n",
        "  return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYuAqUdgKpBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_clean=pd.read_csv('train_clean.csv')\n",
        "test_clean=pd.read_csv('test_clean.csv')\n",
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEPCyRspGwZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_separated=[];batch_separated_clean_train=[];batch_separated_clean_test=[]\n",
        "#train_clean['signal']=normalize(train_clean.signal)\n",
        "#test_clean['signal']=normalize(test_clean.signal)\n",
        "single_batch_size=500000\n",
        "num_of_batch_train=int(train.shape[0]/single_batch_size)\n",
        "num_of_batch_test=int(test.shape[0]/single_batch_size)\n",
        "\n",
        "#train_clean['group']=0;test_clean['group']=0\n",
        "for i in range(num_of_batch_train):\n",
        " # train_clean['group'].iloc[i*single_batch_size:(i+1)*single_batch_size]=i\n",
        "  temp_df=train.iloc[single_batch_size*i:single_batch_size*(i+1)]\n",
        "  batch_separated.append(temp_df)\n",
        "  temp_df=train_clean.iloc[single_batch_size*i:single_batch_size*(i+1)]\n",
        "  batch_separated_clean_train.append(temp_df)\n",
        "for i in range(num_of_batch_test):\n",
        "  #test_clean['group'].iloc[i*single_batch_size:(i+1)*single_batch_size]=i\n",
        "  temp_df=test_clean.iloc[single_batch_size*i:single_batch_size*(i+1)]\n",
        "  batch_separated_clean_test.append(temp_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8P3zxYnQuV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "\n",
        "#train=reduce_mem_usage(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr4qptLZBtvC",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyWaoUBLKo6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_engineering(s,windows_roll,windows_ewm,windows_lag):\n",
        "  ewm = pd.DataFrame();high_pass = pd.DataFrame();low_pass = pd.DataFrame();grads = pd.DataFrame();merged_features=pd.DataFrame()\n",
        "  roll_stats = pd.DataFrame();lead_lag=pd.DataFrame();column_names=[]\n",
        "  n_filts=10\n",
        "  wns = np.logspace(-2, -0.3, n_filts)\n",
        "  n_grads=4\n",
        "  for window in windows_roll:\n",
        "        roll_stats['roll_mean_' + str(window)] = s.rolling(window=window, min_periods=1).mean()\n",
        "        roll_stats['roll_std_' + str(window)] = s.rolling(window=window, min_periods=1).std()\n",
        "        roll_stats['roll_min_' + str(window)] = s.rolling(window=window, min_periods=1).min()\n",
        "        roll_stats['roll_max_' + str(window)] = s.rolling(window=window, min_periods=1).max()\n",
        "        roll_stats['roll_range_' + str(window)] = roll_stats['roll_max_' + str(window)] - roll_stats['roll_min_' + str(window)]\n",
        "        roll_stats['roll_q10_' + str(window)] = s.rolling(window=window, min_periods=1).quantile(0.10)\n",
        "        roll_stats['roll_q25_' + str(window)] = s.rolling(window=window, min_periods=1).quantile(0.25)\n",
        "        roll_stats['roll_q50_' + str(window)] = s.rolling(window=window, min_periods=1).quantile(0.50)\n",
        "        roll_stats['roll_q75_' + str(window)] = s.rolling(window=window, min_periods=1).quantile(0.75)\n",
        "        roll_stats['roll_q90_' + str(window)] = s.rolling(window=window, min_periods=1).quantile(0.90)\n",
        "  roll_stats = roll_stats.fillna(value=0)\n",
        "  #print(roll_stats.shape)\n",
        "  roll_stats=roll_stats.reset_index(drop=True)\n",
        "  for window in windows_lag:\n",
        "    lead_lag['lag_'+str(window)]=s.shift(window)\n",
        "    lead_lag['lead_'+str(window)]=s.shift(-1*window)\n",
        "  lead_lag=lead_lag.fillna(0)\n",
        "  lead_lag=lead_lag.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  g=s.values\n",
        "  for i in range(n_grads):\n",
        "    g = np.gradient(g)\n",
        "    grads['grad_' + str(i+1)] = g\n",
        "  grads=grads.fillna(0)\n",
        "  grads=grads.reset_index(drop=True)\n",
        "  \n",
        "  for wn in wns:\n",
        "    b, a = signal.butter(1, Wn=wn, btype='low')\n",
        "    low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, s.values)\n",
        "    low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, s.values)\n",
        "  low_pass=low_pass.fillna(0)\n",
        "  low_pass=low_pass.reset_index(drop=True)\n",
        "  \n",
        "  for wn in wns:\n",
        "    b, a = signal.butter(1, Wn=wn, btype='high')\n",
        "    high_pass['hihgpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, s.values)\n",
        "    high_pass['hihgpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, s.values)  \n",
        "\n",
        "  high_pass=high_pass.fillna(0)\n",
        "  high_pass=high_pass.reset_index(drop=True)\n",
        "  for window in windows_ewm:\n",
        "    ewm['ewm_mean_' + str(window)] = s.ewm(span=window, min_periods=1).mean()\n",
        "    ewm['ewm_std_' + str(window)] = s.ewm(span=window, min_periods=1).std()\n",
        "  ewm=ewm.fillna(0)\n",
        "  ewm=ewm.reset_index(drop=True)\n",
        "  merged_features=pd.concat([roll_stats,lead_lag,grads,ewm,low_pass,high_pass],axis=1,ignore_index=True) \n",
        "  #merged_features=merged_features.append([roll_stats,lead_lag,grads,ewm,low_pass,high_pass],)\n",
        "  #print(grads.shape,low_pass.shape,high_pass.shape,ewm.shape,lead_lag.shape,roll_stats.shape)\n",
        "  #print(\"aaa\")\n",
        "\n",
        "  column_names=list(roll_stats.columns)+list(lead_lag.columns)+list(grads.columns)+list(ewm.columns)+list(low_pass.columns)+list(high_pass.columns)\n",
        "  idxx=[list(roll_stats.columns),list(lead_lag.columns),list(grads.columns),list(ewm.columns),list(low_pass.columns),list(high_pass.columns)]\n",
        "    #column_names=list(lead_lag.columns)+list(grads.columns)+list(ewm.columns)+list(low_pass.columns)+list(high_pass.columns)\n",
        "  #print(merged_features.shape)\n",
        "  return merged_features,column_names,idxx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCoxTgwLyme",
        "colab_type": "code",
        "outputId": "ffd29ea3-eb1a-48d1-a5ee-e19e7cbcc561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "windows_roll=[10,50,100,500];windows_ewm=[10,50,100];windows_lag=[1,2,3];new_features=pd.DataFrame()\n",
        "temp_df=pd.DataFrame()\n",
        "\n",
        "for i in tqdm.tqdm(range(num_of_batch_train)):  \n",
        "  temp_df,columns,idxx=feature_engineering(batch_separated_clean_train[i].signal,windows_roll,windows_ewm,windows_lag)\n",
        "  #new_features=pd.concat([new_features,temp_df],axis=0,ignore_index=True)\n",
        "  new_features=new_features.append(temp_df)\n",
        "  \n",
        "col_change=dict(zip(temp_df.columns,columns))\n",
        "new_features=reduce_mem_usage(new_features)\n",
        "new_features=new_features.reset_index(drop=True)\n",
        "train=pd.concat([train_clean,new_features],axis=1)\n",
        "train.rename(columns=col_change,inplace=True)\n",
        "\n",
        "train['sig2']=train['signal']**2\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:18<00:00,  7.81s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 953.67 Mb (74.2% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I7EZAHfxB15",
        "colab_type": "code",
        "outputId": "2fc5da72-cf1c-4623-e152-2da3fbb9be53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "new_features=pd.DataFrame();temp_df=pd.DataFrame()\n",
        "\n",
        "for i in tqdm.tqdm(range(num_of_batch_test)):  \n",
        "  temp_df,columns,idxx=feature_engineering(batch_separated_clean_test[i].signal,windows_roll,windows_ewm,windows_lag)\n",
        "  #new_features=pd.concat([new_features,temp_df],axis=0,ignore_index=True)\n",
        "  new_features=new_features.append(temp_df)\n",
        "  \n",
        "col_change=dict(zip(temp_df.columns,columns))\n",
        "new_features=reduce_mem_usage(new_features)\n",
        "new_features=new_features.reset_index(drop=True)\n",
        "test=pd.concat([test_clean,new_features],axis=1)\n",
        "test.rename(columns=col_change,inplace=True)\n",
        "test['sig2']=test['signal']**2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:28<00:00,  7.24s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 381.47 Mb (74.2% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vakL1bB4jV",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih90IC7zMgGD",
        "colab_type": "code",
        "outputId": "882faae9-86bf-41e2-922d-7e42cc5199bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "y=train.open_channels\n",
        "X=train.drop(['time','open_channels'],axis=1)\n",
        "\n",
        "#X=X[new_cols]\n",
        "FEATURES=X.columns\n",
        "x_train, x_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2)\n",
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000000, 98)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSLEUSOuFAv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test.drop('time',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCuT_KVwxIyG",
        "colab_type": "code",
        "outputId": "fc9034fa-6cca-4e83-caa9-82337557e573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "def create_mpl(shape):\n",
        "    '''\n",
        "    Returns a keras model\n",
        "    '''\n",
        "    print(\"bb\")\n",
        "    \n",
        "    X_input = L.Input(shape)\n",
        "    print(\"aa\")\n",
        "    X = L.Dense(150, activation='relu')(X_input)\n",
        "    #X = L.Dropout(0.25)(X)\n",
        "    #X = L.Dense(150, activation='relu')(X)\n",
        "\n",
        "    X = L.Dense(125, activation='relu')(X)\n",
        "    #X = L.Dropout(0.25)(X)\n",
        "    X = L.Dense(100, activation='relu')(X)\n",
        "    X = L.Dense(75, activation='relu')(X)\n",
        "\n",
        "    X = L.Dense(50, activation='relu')(X)\n",
        "    X = L.Dense(25, activation='relu')(X)\n",
        "    X = L.Dense(11, activation='softmax')(X)\n",
        "    \n",
        "    model = Model(inputs=X_input, outputs=X)\n",
        "    print(shape)\n",
        "    return model\n",
        "\n",
        "\n",
        "mlp = create_mpl(x_train[0].shape)\n",
        "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "print(mlp.summary())\n",
        "\n",
        "def get_class_weight(classes):\n",
        "    '''\n",
        "    Weight of the class is inversely proportional to the population of the class\n",
        "    '''\n",
        "    hist, _ = np.histogram(classes, bins=np.arange(12)-0.5)\n",
        "    class_weight = hist.sum()/hist\n",
        "    \n",
        "    return class_weight\n",
        "\n",
        "class_weight = get_class_weight(y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bb\n",
            "aa\n",
            "(98,)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 98)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 150)               14850     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 125)               18875     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               12600     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 75)                7575      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                3800      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 11)                286       \n",
            "=================================================================\n",
            "Total params: 59,261\n",
            "Trainable params: 59,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u854_5xj4ZQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MacroF1(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, model, inputs, targets):\n",
        "        self.model = model\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        pred = np.argmax(self.model.predict(self.inputs), axis = -1)\n",
        "        score = f1_score(self.targets, pred, average = 'macro')\n",
        "        print(f'F1 Macro Score: {score:.5f}')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kE7E1RsxP7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folds=5;epochs=40\n",
        "kf = KFold(n_splits=folds, shuffle=True, random_state=667)\n",
        "fold=1\n",
        "preds_ = np.zeros((len(test), 11))\n",
        "\n",
        "for train_index, val_index in kf.split(X, y):\n",
        "      print(f'====== Fold {fold:0.0f} of {folds} ======')\n",
        "\n",
        "      train_X = X.iloc[train_index]\n",
        "      val_X = X.iloc[val_index]\n",
        "      train_y = y.iloc[train_index]\n",
        "      val_y = y.iloc[val_index]\n",
        "    \n",
        "      mlp.fit(x=train_X, y=train_y, epochs=epochs, batch_size=1024, class_weight=class_weight,callbacks=[MacroF1(mlp,x_test,y_test)])\n",
        "\n",
        "      f1=f1_score(val_y,np.argmax(mlp.predict(val_X),axis=-1),average='macro')\n",
        "      print(f\"F1-Score for classifier of fold {fold} \",\" : \",f1)\n",
        "      preds_proba=mlp.predict(test) / folds\n",
        "      preds_ += preds_proba\n",
        "    \n",
        "      fold+=1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-0kIpIjFa5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv')\n",
        "sub['open_channels'] = np.argmax(preds_, axis = 1).astype(int)\n",
        "sub.to_csv('submission_mlp.csv', index=False, float_format='%.4f')\n",
        "files.download('submission_mlp.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND2seGoGFaxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}